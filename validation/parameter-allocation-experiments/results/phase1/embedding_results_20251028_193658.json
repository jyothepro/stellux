[
  {
    "exp_name": "phase1_emb25",
    "status": "failed",
    "elapsed_seconds": 4.685407638549805,
    "error": "Command '['/home/ubuntu/stellux/validation/parameter-allocation-experiments/venv/bin/python', 'run_experiment.py', '--config', 'configs/phase1_embedding_sweep.yaml', '--exp', 'phase1_emb25']' returned non-zero exit status 1.",
    "stdout": "                0       0.00%\n  (tied={config.tied_lm_head})\n--------------------------------------------------------------------------------\nTransformer Backbone:                6,153,840      63.31%\n  Attention (per layer)                186,624\n  FFN/SwiGLU (per layer)               371,952\n  LayerNorm (per layer)                    864\n  Num layers                                11\nFinal LayerNorm                            432       0.00%\n--------------------------------------------------------------------------------\nTOTAL                                9,720,864       100.0%\n================================================================================\n\nModel Configuration:\n  d_model: 216\n  d_ff: 574\n  n_layers: 11\n  n_heads: 8\n  vocab_size: 16000\n  embedding_ratio: 35.00%\n  glu_expansion: 2.66x\n  tied_lm_head: True\n\nTarget params: 10,000,000\nActual params: 9,720,864\nDifference: -279,136 (-2.79%)\n================================================================================\n",
    "stderr": " max_steps=-1\n2025-10-28 19:36:56,292 - train - INFO - ================================================================================\n\nEpoch 1/1:   0%|          | 0/1148 [00:00<?, ?it/s]\nEpoch 1/1:   0%|          | 1/1148 [00:00<13:38,  1.40it/s]\nEpoch 1/1:   0%|          | 1/1148 [00:00<16:48,  1.14it/s]\n2025-10-28 19:36:57,179 - __main__ - ERROR - Experiment failed: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 22.07 GiB of which 97.81 MiB is free. Process 7464 has 9.39 GiB memory in use. Including non-PyTorch memory, this process has 5.13 GiB memory in use. Process 7463 has 7.43 GiB memory in use. Of the allocated memory 4.36 GiB is allocated by PyTorch, and 513.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
  },
  {
    "exp_name": "phase1_emb35",
    "status": "failed",
    "elapsed_seconds": 4.8827760219573975,
    "error": "Command '['/home/ubuntu/stellux/validation/parameter-allocation-experiments/venv/bin/python', 'run_experiment.py', '--config', 'configs/phase1_embedding_sweep.yaml', '--exp', 'phase1_emb35']' returned non-zero exit status 1.",
    "stdout": "                0       0.00%\n  (tied={config.tied_lm_head})\n--------------------------------------------------------------------------------\nTransformer Backbone:                6,153,840      63.31%\n  Attention (per layer)                186,624\n  FFN/SwiGLU (per layer)               371,952\n  LayerNorm (per layer)                    864\n  Num layers                                11\nFinal LayerNorm                            432       0.00%\n--------------------------------------------------------------------------------\nTOTAL                                9,720,864       100.0%\n================================================================================\n\nModel Configuration:\n  d_model: 216\n  d_ff: 574\n  n_layers: 11\n  n_heads: 8\n  vocab_size: 16000\n  embedding_ratio: 35.00%\n  glu_expansion: 2.66x\n  tied_lm_head: True\n\nTarget params: 10,000,000\nActual params: 9,720,864\nDifference: -279,136 (-2.79%)\n================================================================================\n",
    "stderr": "max_steps=-1\n2025-10-28 19:36:56,290 - train - INFO - ================================================================================\n\nEpoch 1/1:   0%|          | 0/1148 [00:00<?, ?it/s]\nEpoch 1/1:   0%|          | 1/1148 [00:00<13:38,  1.40it/s]\nEpoch 1/1:   0%|          | 1/1148 [00:00<18:38,  1.03it/s]\n2025-10-28 19:36:57,267 - __main__ - ERROR - Experiment failed: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 22.07 GiB of which 141.81 MiB is free. Process 7464 has 9.39 GiB memory in use. Process 7462 has 5.13 GiB memory in use. Including non-PyTorch memory, this process has 7.39 GiB memory in use. Of the allocated memory 6.31 GiB is allocated by PyTorch, and 821.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
  },
  {
    "exp_name": "phase1_emb45",
    "status": "failed",
    "elapsed_seconds": 4.9190521240234375,
    "error": "Command '['/home/ubuntu/stellux/validation/parameter-allocation-experiments/venv/bin/python', 'run_experiment.py', '--config', 'configs/phase1_embedding_sweep.yaml', '--exp', 'phase1_emb45']' returned non-zero exit status 1.",
    "stdout": "                0       0.00%\n  (tied={config.tied_lm_head})\n--------------------------------------------------------------------------------\nTransformer Backbone:                6,153,840      63.31%\n  Attention (per layer)                186,624\n  FFN/SwiGLU (per layer)               371,952\n  LayerNorm (per layer)                    864\n  Num layers                                11\nFinal LayerNorm                            432       0.00%\n--------------------------------------------------------------------------------\nTOTAL                                9,720,864       100.0%\n================================================================================\n\nModel Configuration:\n  d_model: 216\n  d_ff: 574\n  n_layers: 11\n  n_heads: 8\n  vocab_size: 16000\n  embedding_ratio: 35.00%\n  glu_expansion: 2.66x\n  tied_lm_head: True\n\nTarget params: 10,000,000\nActual params: 9,720,864\nDifference: -279,136 (-2.79%)\n================================================================================\n",
    "stderr": "max_steps=-1\n2025-10-28 19:36:56,289 - train - INFO - ================================================================================\n\nEpoch 1/1:   0%|          | 0/1148 [00:00<?, ?it/s]\nEpoch 1/1:   0%|          | 1/1148 [00:00<13:37,  1.40it/s]\nEpoch 1/1:   0%|          | 1/1148 [00:00<18:58,  1.01it/s]\n2025-10-28 19:36:57,283 - __main__ - ERROR - Experiment failed: CUDA out of memory. Tried to allocate 828.00 MiB. GPU 0 has a total capacity of 22.07 GiB of which 185.81 MiB is free. Including non-PyTorch memory, this process has 9.35 GiB memory in use. Process 7462 has 5.13 GiB memory in use. Process 7463 has 7.39 GiB memory in use. Of the allocated memory 8.29 GiB is allocated by PyTorch, and 801.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
  }
]